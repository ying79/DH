# DH 

#### ğŸ“š *An Assignment of the Digital Humanities Course* 

## ğŸ’¬ Japanese Literature Name Finder (RAG-based Web App)

This project is a simple Retrieval-Augmented Generation (RAG) web application that allows users to search for where a given kanji name appears in classical Japanese literature. It uses é’ç©ºæ–‡åº« (Aozora Bunko) as the text source and demonstrates the idea of combining NLP search with conversational AI interaction.

### ğŸŒ¸ Project Overview

When a user inputs a kanji name (e.g. ã€Œç‘©ã€), the system searches downloaded Japanese literary works from Aozora Bunko, finds matching contexts, and summarizes the results in natural Japanese sentences.

This project is developed for the Digital Humanities course and also serves as a base framework for future expansion.

### ğŸ§© System Architecture

*Streamlit Frontend (UI)*

- Chat-style user input
- Display matched excerpts
- Show source references

*RAG Core (Python Backend)*

- Text Preprocessing
- Chunking & Embeddings
- Vector Search (FAISS)
- Gemini LLM Generation

*Aozora Bunko Dataset*

- .txt files (UTF-8)
- Metadata (title, author)

### âš™ï¸ Tech Stack

| Layer | Tool / Library | Description |
|-------|----------------|--------------|
| Frontend | Streamlit | Interactive web app interface |
| Backend | Python| Main development language |
| Embeddings | Google Gemini Embeddings API | Convert text chunks into vectors |
| Vector DB | FAISS or Chroma | Efficient similarity search |
| LLM | Gemini | Generate summarized answers |
| Data | Aozora Bunko | Public domain Japanese literature |


### ğŸ“‚ Project Structure
```
project_root/
â”œâ”€â”€ app.py â€” Streamlit web interface
â”œâ”€â”€ rag_core.py â€” Main RAG logic (embedding, search, generation)
â”œâ”€â”€ requirements.txt â€” Python dependencies
â”œâ”€â”€ config.yaml â€” API keys & path settings (excluded from repo)
â”œâ”€â”€ data/ â€” Text corpus folder
â”‚â€ƒâ”œâ”€â”€ botchan.txt
â”‚â€ƒâ”œâ”€â”€ rashomon.txt
â”‚â€ƒâ””â”€â”€ ...
â””â”€â”€ vectorstore/ â€” Saved embeddings or FAISS index
```




### ğŸ§  Workflow Summary

*Preprocessing* â€“ Parse and preserve ruby annotations from Aozora texts to retain the original readings given by authors, while cleaning unnecessary markup and splitting the text into semantic chunks.

*Embedding* â€“ Generate semantic embeddings for each chunk using Gemini Embeddings API.

*Storage* â€“ Save all embeddings to FAISS or Chroma vector database.

*Retrieval* â€“ Convert user query into embedding and search for similar text.

*Generation* â€“ Feed top-k matched passages into Gemini model to summarize and display sources.



### ğŸ’¡ References


é’ç©ºæ–‡åº«: https://www.aozora.gr.jp/   
FAISS: https://github.com/facebookresearch/faiss  
Streamlit Docs: https://docs.streamlit.io/  
Google Generative AI SDK: https://ai.google.dev/  
