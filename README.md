# DH 

#### ğŸ“š *An Assignment for the Digital Humanities Course* 

---

## ğŸ¯ Japanese Literary Name-Kanji Context Finder (RAG-based Web App)

**Japanese Literary Name-Kanji Context Finder** is a lightweight **Retrieval-Augmented Generation (RAG)** system that searches for where a given kanji character appears within classical Japanese literature from **Aozora Bunko (é’ç©ºæ–‡åº«)**.
It demonstrates how **text preprocessing**, **semantic embeddings**, **vector search**, and **LLM-based generation** can be combined to build a practical tool for ***Digital Humanities*** research.

This project was created as an assignment for the *Digital Humanities* course and also serves as a reusable mini-framework for RAG-based text exploration.

---

### ğŸŒ¸ Project Overview

When a user inputs a kanji (e.g., **ã€Œç‘©ã€**), the system:

1. **Searches all Aozora texts**
2. **Retrieves the sentence and paragraph containing the kanji**
3. **Links the matched context to title / author / Aozora card**
4. **Merges curated + generated kanji meanings**
5. **Uses Gemini + FAISS to produce a clean RAG-based explanation**

This project applies **modern NLP + vector search + LLM reasoning**  
to classical Japanese literature, making kanji-centric reading and analysis  
**fast, interactive, and scalable.**

---

### ğŸ› ï¸ Tech Stack

| Layer | Tool / Library | Description |
|-------|----------------|--------------|
| Frontend | Streamlit | Interactive web app interface |
| Backend | Python| Main development language |
| Embeddings | Google Gemini Embeddings API | Convert text chunks into vectors |
| Vector DB | FAISS  | Efficient similarity search |
| LLM | Gemini | Generate summarized answers |
| Data | Aozora Bunko | Public domain Japanese literature |

---

### ğŸ§© System Architecture


| Layer | Components | Description |
|-------|------------|-------------|
| **Streamlit Frontend (UI)** | â€¢ Chat-style input<br>â€¢ Display matched excerpts<br>â€¢ Show source references | Handles user interaction and displays RAG results in a conversational interface. |
| **RAG Core (Python Backend)** | â€¢ Text preprocessing<br>â€¢ Chunking & embeddings<br>â€¢ Vector search (FAISS)<br>â€¢ Gemini LLM generation | Processes texts, builds embeddings, retrieves relevant excerpts, and generates explanations. |
| **Aozora Bunko Dataset** | â€¢ UTF-8 `.txt` files<br>â€¢ Metadata: title, author | Raw corpus used for retrieval, including downloaded classical literature. |

---

### ğŸ“‚ Project Structure

```
DH/
â”œâ”€â”€ app_chat.py                   # Streamlit chat UI 
â”œâ”€â”€ rag_core.py                   # RAG pipeline + paragraph index builder (--build)
â”œâ”€â”€ aozora_downloader.py          # Downloads & converts Aozora Bunko texts
â”œâ”€â”€ build_char_semantic.py        # Builds kanji semantics (--defs) + kanji FAISS index (--index)
â”œâ”€â”€ faiss_inspect.py              # Debug tool for FAISS index
â”œâ”€â”€ make_missing_sidecars.py      # Utility script: regenerate missing metadata sidecar files for Aozora texts
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ config.yaml                   # API keys & path settings (excluded from repo)
â”‚
â”œâ”€â”€ data/ (excluded from repo)
â”‚   â”œâ”€â”€ *.txt                     # Aozora UTF-8 texts
â”‚   â”œâ”€â”€ *.meta.json               # Metadata sidecars for corpus files; required for RAG indexing
â”‚   â”œâ”€â”€ kanji_semantic.json       # user-curated semantics 
â”‚   â””â”€â”€ kanji_semantic_all.jsonl  # auto-generated semantics (--defs) 
â”‚
â””â”€â”€ index/ (excluded from repo)
â”‚    â”œâ”€â”€ char_semantic/
â”‚    â”‚     â”œâ”€â”€ faiss_char_semantic.faiss   # kanji-level FAISS index
â”‚    â”‚     â””â”€â”€ char_vocab.jsonl            # kanji-level metadata
â”‚    â””â”€â”€ faiss/
â”‚          â”œâ”€â”€ vectors.faiss               # paragraph-level index (rag_core.py --build)
â”‚          â””â”€â”€ metadata.jsonl              # paragraph-level metadata
â”‚ 
â”œâ”€â”€ .gitignore                    # Git ignore rules (exclude cache, index files, API keys, etc.)
â””â”€â”€ README.md                     # Main project overview, workflow description, and usage instructions

```

---

### ğŸ”„ End-to-End Workflow

```mermaid
flowchart TD

    %% ---------- Node Styles ----------
    classDef down fill:#e3f2fd,stroke:#1e88e5,stroke-width:1.5px;
    classDef build fill:#fff3e0,stroke:#fb8c00,stroke-width:1.5px;
    classDef index fill:#e8f5e9,stroke:#43a047,stroke-width:1.5px;
    classDef para fill:#e0f7fa,stroke:#00838f,stroke-width:1.5px;
    classDef rag fill:#ede7f6,stroke:#8e24aa,stroke-width:1.5px;
    classDef ui fill:#fce4ec,stroke:#e91e63,stroke-width:1.5px;
    classDef user fill:#f5f5f5,stroke:#616161,stroke-width:1px;

    %% ---------- Flow ----------
    A["Aozora Bunko"]:::down --> B["aozora_downloader.py â€” download & convert"]:::down
    B --> C["data/*.txt<br/>data/*.meta.json"]:::down

    %% ---- char-level semantic workflow ----
    C --> D["build_char_semantic.py --defs<br/>â€” build kanji semantics"]:::build
    D --> E["kanji_semantic_all.jsonl"]:::build
    
    C --> F["build_char_semantic.py --index<br/>â€” build kanji FAISS index"]:::index
    F --> G["faiss_char_semantic.faiss<br/>char_vocab.jsonl (kanji-level semantic index)"]:::index

    %% ---- paragraph-level RAG index ----
    C --> K["rag_core.py --build<br/>â€” build paragraph index"]:::para
    K --> L["vectors.faiss<br/>metadata.jsonl (paragraph chunks)"]:::para

    %% ---- combine into RAG ----
    E --> H["rag_core.py â€” RAG retrieval & explanation"]:::rag
    G --> H
    L --> H

    H --> I["app_chat.py â€” Streamlit UI"]:::ui
    I --> J["User query â†’ results"]:::user

```

---

### âš™ï¸ Configuration (config.yaml)

This project uses a single configuration file, config.yaml, which stores API keys, model choices, and all index/corpus paths.
A valid configuration is required before running any of the build scripts (--defs, --index, --build) or launching the Streamlit app.

Below is the full structure used by this project:

```bash
api:
  # gemini_api_key: ""     # Add your Gemini API key here

models:
  embed: "text-embedding-004"
  llm: "gemini-2.0-flash"

chunking:
  max_chars: 1200
  overlap: 120

embedding:
  batch_size: 128
  normalize: true

index:
  dir: "index/faiss"
  metadata_jsonl: "metadata.jsonl"
  faiss_index: "vectors.faiss"

char_index:
  dir: index/char_semantic
  faiss: faiss_char_semantic.faiss
  vocab: char_vocab.jsonl
  seed_json: data/kanji_semantic.json  # optional curated seed dictionary
```
***Notes***

- ***gemini_api_key*** must be provided by the user.(The key is excluded from the repository for security.) 

- All ***index directories*** (index/faiss, index/char_semantic/) will be created automatically by the scripts. 

- data/ and index/ contents are ***NOT*** included in the repo; users must generate them via the commands provided in the next section. 

- ***seed_json*** is optional and used for enriching the kanji semantic dictionary during incremental updates. 


---

### ğŸ§ª Build & Usage Commands
#### 1. Download Aozora Texts

Download specific author:

```bash
python aozora_downloader.py --author "å¤ç›®æ¼±çŸ³"
```

Random N works:

```bash
python aozora_downloader.py --random 5
```

Download by card ID:

```bash
python aozora_downloader.py --card-id 7799
```
#### 2. Build Kanji Semantics (Two-Step)
##### Step A â€” Generate semantic dictionary
```bash
python build_char_semantic.py --defs

Outputs:

kanji_semantic_all.jsonl
```
##### Step B â€” Build FAISS index (kanji-level)
```bash
python build_char_semantic.py --index

Outputs:

index/char_semantic/faiss_char_semantic.faiss
index/char_semantic/char_vocab.jsonl
```
#### 3. Build Paragraph-Level Index (RAG Core)
```bash
python rag_core.py --build

Outputs:

index/faiss/vectors.faiss
index/faiss/metadata.jsonl

This index enables full-paragraph context retrieval.
```

#### 4. Run the Web App

```bash
streamlit run app_chat.py
```

---

### ğŸ§  Workflow Summary

**Preprocessing** â€“ Download Aozora texts, normalize formatting, clean markup, and split content into sentences and paragraphs. Generate per-text sidecar metadata (`*.meta.json`).

**Kanji Semantics** â€“ Build curated + auto-generated kanji meanings (`--defs`), then create a kanji-level FAISS index (`--index`).

**Embedding & Indexing** â€“ Use Gemini Embeddings to encode paragraphs and store them in a paragraph-level FAISS index (`rag_core.py --build`).

**Retrieval** â€“ Convert the userâ€™s kanji into embeddings, search both kanji-level and paragraph-level indexes, and gather matched contexts with metadata.

**Generation** â€“ Combine context + kanji meanings and feed them to Gemini to produce a concise, literature-aware Japanese explanation.


---

### ğŸ’¡ References


é’ç©ºæ–‡åº«: https://www.aozora.gr.jp/   
FAISS: https://github.com/facebookresearch/faiss  
Streamlit Docs: https://docs.streamlit.io/  
Google Generative AI SDK: https://ai.google.dev/   

---

### ğŸ“‘ Citation

If you find this project helpful for your study, research, or teaching,
you may reference it using the DOI below:

[![DOI](https://zenodo.org/badge/1068996564.svg)](https://doi.org/10.5281/zenodo.17667425)

